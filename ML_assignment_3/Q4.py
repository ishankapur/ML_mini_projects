# -*- coding: utf-8 -*-
"""ml3- q4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16xumN11kMddlVI-7T43jJ2b2dYHFEmxK
"""

#importing libraries
import torch
import torchvision
from torchvision import transforms
import torch.nn as NN
import torch.nn.functional as funct
import matplotlib.pyplot as plt
import torch.optim as optim
import pandas as pd
import numpy as np
import pickle
from PIL import Image as im

#loading data for train and test using pickle
train = pickle.load(open("train_CIFAR.pickle",'rb'))
test = pickle.load(open("test_CIFAR.pickle",'rb'))

#splitting data
train_X = train['X']
train_Y = train['Y']
test_X = test['X']
test_Y = test['Y']

#visualizing data using TSNE, first creating useful features using PCA wih 0.95 variation and then applying TSNE
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA

plt.figure(figsize=(20,10))
pca = PCA(0.95)
pca = pca.fit_transform(train_X)

# using TSNE componenets = 2

tsne =TSNE(n_components=2)
tsne = tsne.fit_transform(pca)

#plotting the graph using scatterplot

colors = ['cyan','violet']
for i in range(len(colors)):
    data = tsne[train_Y==i]
    plt.scatter(data[:,0],data[:,1],label="Class "+str(i),c=colors[i])
plt.xlabel("Axis-1")
plt.ylabel("Axis-2")
plt.legend()
plt.show()

#counting unique elements in train set for EDA
unique_elements, counts_elements = np.unique(train_Y, return_counts=True)
print("CLASS DISTRIBUTION OF TRAINING DATA")
for i in range(len(unique_elements)):
  print("count of class ",unique_elements[i],":=  ", counts_elements[i])

#counting unique elements in test set for EDA
unique_elements, counts_elements = np.unique(test_Y, return_counts=True)
print("CLASS DISTRIBUTION OF TESTING DATA")
for i in range(len(unique_elements)):
  print("count of class ",unique_elements[i],":=  ", counts_elements[i])

#reshaping train and test data
train_X = train_X.reshape(-1,3,32,32).transpose(0,2,3,1)
test_X = test_X.reshape(-1,3,32,32).transpose(0,2,3,1)


#code commented but was fr displaying images in EDA

# from google.colab.patches import cv2_imshow
# import random
# print("5 Train Images")
# for i in range(5):
#   im = random.randint(0,train_X.shape[0]-1)
#   cv2_imshow(train_X[i])
#   print(train_Y[i])
# print("5 Test Images")
# for i in range(5):
#   im= random.randint(0,test_X.shape[0]-1)
#   cv2_imshow(test_X[i])
#   print(test_Y[i])


#loading the ALEX_MODEL as done in documentation

ALEX_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)
if torch.cuda.is_available(): #line to check if you sysytem is connected to GPU or not
  ALEX_model = ALEX_model.to('cuda') #sending model to CUDA such that it will process images and run on the GPU

#pre-processing steps for image as mentioned in the documentation
preprocess = transforms.Compose([transforms.Resize((227,227)),transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),])

# running ALEX model on dataset and creating a dataframe 
#array to store numpys of output from fc8 layer
array_of_nps = []
for i in range(train_X.shape[0]):
  image = im.fromarray(train_X[i]) #convert array to image
  im_processed = preprocess(image) #preprocess it as mentioned in documentation
  im_processed = im_processed.unsqueeze(0) #unsqueezing the image
  if torch.cuda.is_available(): #checking if GPU is available
    im_processed = im_processed.to('cuda') #send it to the GPU
  op = ALEX_model(im_processed)[0] #taking output of fc8 layer
  #print(op)
  im_ans = op.to('cpu') #sending it back to CPU
  im_ans = im_ans.detach() #detaching image from GPU
  im_ans = im_ans.numpy().tolist() #converting to python array
  array_of_nps.append(im_ans) # appending to array of output
data_frame = pd.DataFrame.from_records(array_of_nps) # converting tpo dataframe
data_frame[1000] = train_Y
data_frame.to_csv("INPUT_FOR_PYTORCH_TRAIN.csv",index= False) # seding to CSV

#same things for test data
array_of_nps = []
for i in range(test_X.shape[0]):
  image = im.fromarray(test_X[i])
  im_processed = preprocess(image)
  im_processed = im_processed.unsqueeze(0)
  if torch.cuda.is_available():
    im_processed = im_processed.to('cuda')
  op = ALEX_model(im_processed)[0]
  #print(op)
  im_ans = op.to('cpu')
  im_ans = im_ans.detach()
  im_ans = im_ans.numpy().tolist()
  array_of_nps.append(im_ans)

data_frame = pd.DataFrame.from_records(array_of_nps)
data_frame[1000] = test_Y

data_frame.to_csv("INPUT_FOR_PYTORCH_TEST.csv",index= False)


#applying pytorch NN model now
train = pd.read_csv("INPUT_FOR_PYTORCH_TRAIN.csv")
test = pd.read_csv("INPUT_FOR_PYTORCH_TEST.csv")

#sending all data to GPU
if torch.cuda.is_available():  
  train_X = torch.from_numpy(train[train.columns[:-1]].to_numpy().astype('float32')).to('cuda')
  train_Y = torch.from_numpy(train[train.columns[-1:]].to_numpy()).to('cuda')
  test_X = torch.from_numpy(test[test.columns[:-1]].to_numpy().astype('float32')).to('cuda')
  test_Y = torch.from_numpy(test[test.columns[-1:]].to_numpy()).to('cuda')

#declaring class nureal network for torch
class Nueral_Net(NN.Module):
    def __init__(self):
        super().__init__()
        #declaring layers
        self.layer_1 = NN.Linear(1000, 512)
        self.layer_2 = NN.Linear(512,256)
        self.layer_3 = NN.Linear(256, 2)
    def forward(self, x):
      #overriding forward function
        x = funct.relu(self.layer_1(x))
        x = funct.relu(self.layer_2(x))
        x = self.layer_3(x)
        return x
#declaring object of the class
nn_torch = Nueral_Net()
nn_torch.to('cuda')
print(nn_torch)
#declaring loss function 
loss_function = NN.CrossEntropyLoss()
optimizer = optim.Adam(nn_torch.parameters(), lr=0.01) #learning rate
epocs =100 #epocs

loss_function.to('cuda')

train_loss = []
val_loss =[]
iters =[]
for i in range(epocs): 
    iters.append(i+1)
    X = train_X
    y= train_Y 
    #making gradient 0
    nn_torch.zero_grad()
    #getting output for train  and test data 
    output = nn_torch(X)
    val_output = nn_torch(test_X)
    #calculating losses
    loss = loss_function(output, y.T[0]) 
    loss_val = loss_function(val_output,test_Y.T[0])
    #appending losses in aray for plot
    with torch.no_grad():
      train_loss.append(loss.detach())
      val_loss.append(loss_val.detach())
    #backward propogation
    loss.backward() 
    #updae of gradients
    optimizer.step()
    print(loss)
print("training loss :  ", train_loss[-1])
print("test loss :  ", val_loss[-1])
#plotting
plt.title('iteration VS ENTROPY')
plt.plot(iters,train_loss,label = 'training loss')
plt.plot(iters,val_loss, label = 'validation loss')
plt.xlabel('interations')
plt.ylabel('entropy loss')
plt.legend()
plt.show()

#calculating accuracy
with torch.no_grad():
  ypred = nn_torch(train_X)
  Y_test = train_Y.T[0]
  pred =ypred.argmax(1)
  count=0
  for i in range(len(ypred)):
    if (pred[i]==Y_test[i]):
      count+=1
  print("training accuracy  ",count/len(ypred)*100)

with torch.no_grad():
  ypred = nn_torch(test_X)
  Y_test = test_Y.T[0]
  pred =ypred.argmax(1)
  count=0
  for i in range(len(ypred)):
    if (pred[i]==Y_test[i]):
      count+=1
  print("testing accuracy  ",count/len(ypred)*100)

#printing confusion matrix and ROC curve
from sklearn.metrics import confusion_matrix,roc_curve,auc
import seaborn as sns
c = confusion_matrix(Y_test.cpu(),pred.cpu())
sns.heatmap(c,annot = True,cmap="YlGnBu")

plt.ylabel('True values')
plt.xlabel('predicted values')

fpr, tpr, thresholds = roc_curve(Y_test.cpu(), ypred.cpu().numpy()[:,1], pos_label=1)
plt.plot([0, 1], [0, 1], linestyle='--', label='Base Line')
plt.plot(fpr, tpr, linewidth=2, label='ROC Curve (AUC = '+str(auc(fpr, tpr))+')')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for label=1')
plt.legend(loc="lower right")

fpr, tpr, thresholds = roc_curve(Y_test.cpu(), ypred.cpu().numpy()[:,1], pos_label=0)
plt.plot([0, 1], [0, 1], linestyle='--', label='Base Line')
plt.plot(tpr, fpr, linewidth=2, label='ROC Curve (AUC = '+str(auc(tpr, fpr))+')')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for label=0')
plt.legend(loc="lower right")